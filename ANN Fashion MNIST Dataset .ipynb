{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"bmnklUqPZ0yU","executionInfo":{"status":"ok","timestamp":1750398936574,"user_tz":-330,"elapsed":4752,"user":{"displayName":"Utsav Dhandhiya","userId":"17668420785486293554"}}},"outputs":[],"source":["import pandas as pd\n","\n","file_name = '/content/drive/MyDrive/Dataset/fashion-mnist_train.csv'\n","df = pd.read_csv(file_name)\n"]},{"cell_type":"code","source":["df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPaDhHN056bP","executionInfo":{"status":"ok","timestamp":1750398938491,"user_tz":-330,"elapsed":108,"user":{"displayName":"Utsav Dhandhiya","userId":"17668420785486293554"}},"outputId":"8a8bc3f3-3e79-4a52-e54b-021fa171a898"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6999 entries, 0 to 6998\n","Columns: 785 entries, label to pixel784\n","dtypes: int64(785)\n","memory usage: 41.9 MB\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzswqm_pht2U"},"outputs":[],"source":["# Split the dataset into training and test dataset\n","\n","X = df.iloc[:,1:].values\n","y = df.iloc[:,0].values\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=24\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yn0nsUK2lfwZ"},"outputs":[],"source":["# Feature Scaling\n","\n","X_train = X_train / 255.0\n","X_test  = X_test  / 255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHYM-vMwlrUU"},"outputs":[],"source":["# Create Custom Dataset\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","        self.y = torch.tensor(y, dtype=torch.long)  # long for CrossEntropy\n","    def __len__(self):      return len(self.X)\n","    def __getitem__(self, i): return self.X[i], self.y[i]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6azHw_Gn9R3"},"outputs":[],"source":["# Create Train Dataset\n","\n","train_dataset = CustomDataset(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_44Hj20oV4F"},"outputs":[],"source":["# Create Test Dataset\n","\n","test_dataset = CustomDataset(X_test, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRlBQ_dHqU3L"},"outputs":[],"source":["# Create Train & Test dataset loader\n","\n","from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(CustomDataset(X_train, y_train),\n","                          batch_size=32, shuffle=True)\n","test_loader  = DataLoader(CustomDataset(X_test,  y_test),\n","                          batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fftSNSP2rej2"},"outputs":[],"source":["# Create NN module\n","\n","from torch import nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","\n","class NN(nn.Module):\n","\n","  def __init__(self, num_features):\n","\n","    super().__init__()\n","    self.model = nn.Sequential(\n","        nn.Linear(num_features, 128),\n","        nn.ReLU(),\n","        nn.Linear(128, 64),\n","        nn.ReLU(),\n","        nn.Linear(64,10)\n","    )\n","\n","  def forward(self,X):\n","\n","    return self.model(X)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paCKnUzQ3WPe"},"outputs":[],"source":["# Set Values of Epochs & Learning Rate\n","\n","epochs = 1000\n","Learning_rate = 0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XjIWU6B4o2I"},"outputs":[],"source":["# Instantiation of the model\n","model= NN(784)\n","\n","#loss function\n","Loss_fn = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","optimizer = optim.SGD(model.parameters(), lr= Learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uI2wrVN7Y-EL"},"outputs":[],"source":["# Training Loop\n","\n","for epoch in range(epochs):\n","\n","  for batch_features, batch_labels in train_loader:\n","\n","    #Forward pass:\n","    outputs = model(batch_features)\n","\n","    #calculate loss:\n","    loss=Loss_fn(outputs, batch_labels.long())\n","\n","    #back pass:\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    #update grad:\n","    optimizer.step()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1750184489143,"user":{"displayName":"Utsav Dhandhiya","userId":"17668420785486293554"},"user_tz":-330},"id":"U_d3o5iehwe_","outputId":"ddb7bade-c318-4ab4-8065-babaa5bbed61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 84.71%\n"]}],"source":["#Evaluation code:\n","\n","correct = 0\n","total   = 0\n","model.eval()\n","with torch.no_grad():\n","    for Xb, yb in test_loader:\n","        logits = model(Xb)\n","        preds  = logits.argmax(dim=1)\n","        correct += (preds == yb).sum().item()\n","        total   += yb.size(0)\n","\n","print(f\"Test accuracy: {correct/total*100:.2f}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1KxHs2gcwaDb_RJmzgU52D6tmfvMx93rO","authorship_tag":"ABX9TyPY6LhAoJCfcFZ8xlU2MK/4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
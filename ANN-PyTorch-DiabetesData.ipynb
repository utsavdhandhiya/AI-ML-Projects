{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGoElke/uFRDHaJoDhtjHs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"plKKZnp_B8bx"},"outputs":[],"source":["import pandas as pd\n","\n","file_name = '/content/diabetes.csv'\n","df = pd.read_csv(file_name)"]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt"],"metadata":{"id":"HZtVBtP0CV7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X = df.iloc[:,:-1].values\n","y = df.iloc[:,-1].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state= 24)"],"metadata":{"id":"ehHNKtjkCWqC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature Scalling\n","\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"Q1YzN2TmCbY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Custom Dataset\n","\n","class Customdataset(Dataset):\n","    def __init__(self,X,y):\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","        self.y = torch.tensor(y, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]"],"metadata":{"id":"NKol6nk_CeZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = Customdataset(X_train, y_train)\n","test_dataset = Customdataset(X_train, X_test)\n","\n","train_dataloader = DataLoader(Customdataset(X_train, y_train) , batch_size=32, shuffle=True)\n","test_dataloader = DataLoader(Customdataset(X_test, y_test) , batch_size=32, shuffle=False)"],"metadata":{"id":"wUywRfzLChgu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create NN\n","\n","import torch.nn as nn\n","\n","class NN(nn.Module):\n","    def __init__(self):\n","        super(NN, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(8, 28),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(28, 14),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.2),\n","            nn.Linear(14, 2)\n","        )\n","\n","    def forward(self, X):\n","        return self.model(X)\n","\n","    def forward(self, X):\n","        return self.model(X)"],"metadata":{"id":"UomyMymbCin4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Adjust HyperParameter\n","\n","epochs = 500\n","learning_rate= 0.01\n","model = NN()\n","loss = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(),lr=learning_rate)"],"metadata":{"id":"YGU0o4ZoCl48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","\n","model.train\n","\n","for epoch in range(epochs):\n","    for X_batch, y_batch in train_dataloader:\n","\n","        # Convert to float\n","        X_batch = X_batch.float()\n","        y_batch = y_batch.long()\n","\n","        # Forward Pass\n","        outputs = model(X_batch)\n","\n","        # Calculate Loss\n","        loss_value = loss(outputs, y_batch)\n","\n","        # BackProp and Update Param\n","        optimizer.zero_grad()\n","        loss_value.backward()\n","        optimizer.step()"],"metadata":{"id":"Duam0EYaCqjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix\n","\n","def evaluate_model(model, dataloader, task_type='classification', device='cpu'):\n","\n","    model.to(device)\n","    model.eval()\n","\n","    y_true = []\n","    y_pred = []\n","\n","    with torch.no_grad():\n","        for inputs, targets in dataloader:\n","            inputs = inputs.to(device)\n","            targets = targets.to(device)\n","\n","            outputs = model(inputs)\n","\n","            if task_type == 'classification':\n","                _, predicted = torch.max(outputs, 1)  # for multi-class classification\n","                y_pred.extend(predicted.cpu().numpy())\n","                y_true.extend(targets.cpu().numpy())\n","\n","            elif task_type == 'regression':\n","                y_pred.extend(outputs.squeeze().cpu().numpy())\n","                y_true.extend(targets.squeeze().cpu().numpy())\n","\n","    metrics = {}\n","\n","    if task_type == 'classification':\n","        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n","        metrics['report'] = classification_report(y_true, y_pred)\n","        metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)\n","    elif task_type == 'regression':\n","        metrics['mse'] = mean_squared_error(y_true, y_pred)\n","        metrics['rmse'] = mean_squared_error(y_true, y_pred, squared=False)\n","\n","    return metrics"],"metadata":{"id":"ZhFsJ4KCFNfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","test_dataloader = DataLoader(Customdataset(X_test, y_test) , batch_size=32, shuffle=False)\n","metrics = evaluate_model(model, test_dataloader, task_type='classification', device='cpu')\n","\n","print(metrics)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHuZaOKiGgKw","executionInfo":{"status":"ok","timestamp":1750486670334,"user_tz":-330,"elapsed":10,"user":{"displayName":"Utsav Dhandhiya","userId":"17668420785486293554"}},"outputId":"0f0dd4af-de9e-4cf5-8a3d-0b3283002c4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'accuracy': 0.7077922077922078, 'report': '              precision    recall  f1-score   support\\n\\n         0.0       0.70      0.96      0.81        98\\n         1.0       0.79      0.27      0.40        56\\n\\n    accuracy                           0.71       154\\n   macro avg       0.74      0.61      0.60       154\\nweighted avg       0.73      0.71      0.66       154\\n', 'confusion_matrix': array([[94,  4],\n","       [41, 15]])}\n"]}]}]}